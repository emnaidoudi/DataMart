{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, TimestampType, ShortType, DateType\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_Spark():\n",
    "    \n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"simple etl job\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDFWithoutSchema(spark):\n",
    "\n",
    "    df = spark.read.format(\"csv\").option(\"header\", \"true\").load(os.environ[\"HOME\"] + \"/workspace/Spark/Notebooks/data/autos.csv\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDFWithSchema(spark):\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"dateCrawled\", TimestampType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"seller\", StringType(), True),\n",
    "        StructField(\"offerType\", StringType(), True),\n",
    "        StructField(\"price\", LongType(), True),\n",
    "        StructField(\"abtest\", StringType(), True),\n",
    "        StructField(\"vehicleType\", StringType(), True),\n",
    "        StructField(\"yearOfRegistration\", StringType(), True),\n",
    "        StructField(\"gearbox\", StringType(), True),\n",
    "        StructField(\"powerPS\", ShortType(), True),\n",
    "        StructField(\"model\", StringType(), True),\n",
    "        StructField(\"kilometer\", LongType(), True),\n",
    "        StructField(\"monthOfRegistration\", StringType(), True),\n",
    "        StructField(\"fuelType\", StringType(), True),\n",
    "        StructField(\"brand\", StringType(), True),\n",
    "        StructField(\"notRepairedDamage\", StringType(), True),\n",
    "        StructField(\"dateCreated\", DateType(), True),\n",
    "        StructField(\"nrOfPictures\", ShortType(), True),\n",
    "        StructField(\"postalCode\", StringType(), True),\n",
    "        StructField(\"lastSeen\", TimestampType(), True)\n",
    "    ])\n",
    "\n",
    "    df = spark \\\n",
    "        .read \\\n",
    "        .format(\"csv\") \\\n",
    "        .schema(schema)         \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .load(os.environ[\"HOME\"] + \"/workspace/Spark/Notebooks/data/autos.csv\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_drop_data(df):\n",
    "\n",
    "    df_dropped = df.drop(\"dateCrawled\",\"nrOfPictures\",\"lastSeen\")\n",
    "    df_filtered = df_dropped.where(col(\"seller\") != \"gewerblich\")\n",
    "    df_dropped_seller = df_filtered.drop(\"seller\")\n",
    "    df_filtered2 = df_dropped_seller.where(col(\"offerType\") != \"Gesuch\")\n",
    "    df_final = df_filtered2.drop(\"offerType\")\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(cursor):\n",
    "\n",
    "    cursor.execute(\"CREATE TABLE IF NOT EXISTS cars_table \\\n",
    "    (   name VARCHAR(255) NOT NULL, \\\n",
    "        price integer NOT NULL, \\\n",
    "        abtest VARCHAR(255) NOT NULL, \\\n",
    "        vehicleType VARCHAR(255), \\\n",
    "        yearOfRegistration VARCHAR(4) NOT NULL, \\\n",
    "        gearbox VARCHAR(255), \\\n",
    "        powerPS integer NOT NULL, \\\n",
    "        model VARCHAR(255), \\\n",
    "        kilometer integer, \\\n",
    "        monthOfRegistration VARCHAR(255) NOT NULL, \\\n",
    "        fuelType VARCHAR(255), \\\n",
    "        brand VARCHAR(255) NOT NULL, \\\n",
    "        notRepairedDamage VARCHAR(255), \\\n",
    "        dateCreated DATE NOT NULL, \\\n",
    "        postalCode VARCHAR(255) NOT NULL);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_postgresql(df):\n",
    "\n",
    "    cars_seq = [tuple(x) for x in df.collect()]\n",
    "\n",
    "    records_list_template = ','.join(['%s'] * len(cars_seq))\n",
    "\n",
    "    insert_query = \"INSERT INTO cars_table (name, price, abtest, vehicleType, yearOfRegistration, gearbox, powerPS, \\\n",
    "                        model, kilometer, monthOfRegistration, fuelType, brand, notRepairedDamage, dateCreated, postalCode \\\n",
    "                           ) VALUES {}\".format(records_list_template)\n",
    "\n",
    "    return insert_query, cars_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_insterted_data(cursor):\n",
    "\n",
    "    postgreSQL_select_Query = \"select brand, model, price from cars_table\"\n",
    "\n",
    "    cursor.execute(postgreSQL_select_Query)\n",
    "\n",
    "    cars_records = cursor.fetchmany(2)\n",
    "\n",
    "    print(\"Printing 2 rows\")\n",
    "    for row in cars_records:\n",
    "        print(\"Brand = \", row[0], )\n",
    "        print(\"Model = \", row[1])\n",
    "        print(\"Price  = \", row[2], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starting point of every Spark application is the creation of a SparkSession. This is a driver process that maintains all relevant information about your Spark Application and it is also responsible for distributing and scheduling your application across all executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = initialize_Spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadDFWithSchema(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = clean_drop_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "        host = \"localhost\",\n",
    "        port = \"5432\",\n",
    "        database = \"cars\",\n",
    "        user = \"postgres\",\n",
    "        password = \"123456789\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cursor is created out of a connection and it will allow you to communicate with PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "insert_query, cars_seq = write_postgresql(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(insert_query, cars_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing 2 rows\n",
      "('Brand = ', 'volkswagen')\n",
      "('Model = ', 'golf')\n",
      "('Price  = ', 480, '\\n')\n",
      "('Brand = ', 'audi')\n",
      "('Model = ', None)\n",
      "('Price  = ', 18300, '\\n')\n"
     ]
    }
   ],
   "source": [
    "get_insterted_data(cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tbalbiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+------+---------+-----+------+-----------+------------------+-------+-------+-----+---------+-------------------+--------+----------+-----------------+-----------+------------+----------+-------------------+\n",
      "|        dateCrawled|      name|seller|offerType|price|abtest|vehicleType|yearOfRegistration|gearbox|powerPS|model|kilometer|monthOfRegistration|fuelType|     brand|notRepairedDamage|dateCreated|nrOfPictures|postalCode|           lastSeen|\n",
      "+-------------------+----------+------+---------+-----+------+-----------+------------------+-------+-------+-----+---------+-------------------+--------+----------+-----------------+-----------+------------+----------+-------------------+\n",
      "|2016-03-24 11:52:17|Golf_3_1.6|privat|  Angebot|  480|  test|       null|              1993|manuell|      0| golf|   150000|                  0|  benzin|volkswagen|             null| 2016-03-24|           0|     70435|2016-04-07 03:16:57|\n",
      "+-------------------+----------+------+---------+-----+------+-----------+------------------+-------+-------+-----+---------+-------------------+--------+----------+-----------------+-----------+------------+----------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+----------+---------+-----+-------+-----------+------------------+-------+-------+------+---------+-------------------+--------+-------+-----------------+-----------+------------+----------+-------------------+\n",
      "|        dateCrawled|                name|    seller|offerType|price| abtest|vehicleType|yearOfRegistration|gearbox|powerPS| model|kilometer|monthOfRegistration|fuelType|  brand|notRepairedDamage|dateCreated|nrOfPictures|postalCode|           lastSeen|\n",
      "+-------------------+--------------------+----------+---------+-----+-------+-----------+------------------+-------+-------+------+---------+-------------------+--------+-------+-----------------+-----------+------------+----------+-------------------+\n",
      "|2016-03-15 18:06:22|Verkaufe_mehrere_...|gewerblich|  Angebot|  100|control|      kombi|              2000|manuell|      0|megane|   150000|                  8|  benzin|renault|             null| 2016-03-15|           0|     65232|2016-04-06 17:15:37|\n",
      "+-------------------+--------------------+----------+---------+-----+-------+-----------+------------------+-------+-------+------+---------+-------------------+--------+-------+-----------------+-----------+------------+----------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"seller\")==\"gewerblich\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|    seller|\n",
      "+----------+\n",
      "|gewerblich|\n",
      "|      null|\n",
      "|    privat|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"seller\").distinct().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
